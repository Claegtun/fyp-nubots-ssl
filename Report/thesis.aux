\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{3}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The NUgus robots are mainly used by the NUbots teams to compete in RoboCup\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nuguses}{{1.1}{4}{The NUgus robots are mainly used by the NUbots teams to compete in RoboCup\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Scope}{4}{section.1.2}\protected@file@percent }
\citation{argentieri_survey_2015}
\citation{sakavicius_multiple_2022}
\citation{argentieri_survey_2015}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature-Review}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Overview of Methods}{6}{section.2.1}\protected@file@percent }
\citation{rascon_localization_2017}
\citation{argentieri_survey_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The Far Field and the Near Field}{7}{subsection.2.1.1}\protected@file@percent }
\citation{valin_robust_2003}
\citation{argentieri_survey_2015}
\citation{rascon_localization_2017}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Time-Difference of Arrival}{8}{section.2.2}\protected@file@percent }
\citation{argentieri_survey_2015}
\citation{valin_robust_2003}
\citation{valin_robust_2003}
\citation{valin_robust_2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Literature Examples}{9}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Valin et al., 2003, Robust Sound Source Localization Using a Microphone Array on a Mobile Robot}{9}{section*.3}\protected@file@percent }
\citation{valin_robust_2003}
\citation{valin_robust_2003}
\citation{hu_estimation_2009}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The microphone array on top of the mobile robot in \cite  {valin_robust_2003}\relax }}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:valin_2003_robot}{{2.1}{10}{The microphone array on top of the mobile robot in \cite {valin_robust_2003}\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The mean angular error as a function of the distance between the source and the array in \cite  {valin_robust_2003}\relax }}{10}{figure.caption.5}\protected@file@percent }
\newlabel{fig:valin_2003_plot}{{2.2}{10}{The mean angular error as a function of the distance between the source and the array in \cite {valin_robust_2003}\relax }{figure.caption.5}{}}
\citation{hu_estimation_2009}
\citation{hu_estimation_2009}
\@writefile{toc}{\contentsline {subsubsection}{Hu et al., 2009, Estimation of Sound Source Number and Directions Under a Multi-Source Environment}{11}{section*.6}\protected@file@percent }
\citation{chen_sound_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The microphone array in \cite  {hu_estimation_2009}\relax }}{12}{figure.caption.7}\protected@file@percent }
\newlabel{fig:hu_2009_plot}{{2.3}{12}{The microphone array in \cite {hu_estimation_2009}\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Chen \& Xu, 2019, A Sound Source Localization Device Based on Rectangular Pyramid Structure for Mobile Robot}{12}{section*.8}\protected@file@percent }
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The microphone array in \cite  {chen_sound_2019}\relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{fig:chen_2019_array}{{2.4}{13}{The microphone array in \cite {chen_sound_2019}\relax }{figure.caption.9}{}}
\citation{bechler_system_2004}
\citation{kim_robust_2008}
\citation{manamperi_drone_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The error in distance as a function of distance for different SNRs in \cite  {chen_sound_2019}\relax }}{14}{figure.caption.10}\protected@file@percent }
\newlabel{fig:chen_2019_distance_SNR}{{2.5}{14}{The error in distance as a function of distance for different SNRs in \cite {chen_sound_2019}\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Bechler et al., 2004, System for Robust 3D Speaker Tracking Using Microphone Array Measurements}{14}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kim et al., 2008, Robust Estimation of Sound Direction for Robot Interface}{14}{section*.12}\protected@file@percent }
\citation{manamperi_drone_2022}
\citation{manamperi_drone_2022}
\citation{manamperi_drone_2022}
\citation{manamperi_drone_2022}
\@writefile{toc}{\contentsline {subsubsection}{Manamperi et al., 2022, Drone Audition: Sound Source Localization Using On-Board Microphones}{15}{section*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The microphone array on the drone (a) and each pair (b) in \cite  {manamperi_drone_2022}\relax }}{15}{figure.caption.14}\protected@file@percent }
\newlabel{fig:manamperi_2022_array}{{2.6}{15}{The microphone array on the drone (a) and each pair (b) in \cite {manamperi_drone_2022}\relax }{figure.caption.14}{}}
\citation{mahajan_3d_2001}
\citation{rascon_localization_2017}
\citation{rascon_localization_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The energy maps for MUSIC (a), GEVD-MUSIC (b), GCC-PHAT (c), and the proposed method (d) at an SNR of -30 \si {dB} in \cite  {manamperi_drone_2022}\relax }}{16}{figure.caption.15}\protected@file@percent }
\newlabel{fig:manamperi_2022_map_n30}{{2.7}{16}{The energy maps for MUSIC (a), GEVD-MUSIC (b), GCC-PHAT (c), and the proposed method (d) at an SNR of -30 \si {dB} in \cite {manamperi_drone_2022}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Mahajan \& Walworth, 2001, 3D Position Sensing Using the Differences in the Time-of-Flights from a Wave Source to Various Receivers}{16}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Distance}{16}{subsection.2.2.2}\protected@file@percent }
\citation{gustafsson_source_2003}
\citation{brandstein_robust_1997}
\citation{valin_robust_2003}
\citation{clifford_calculating_2010}
\citation{kwon_analysis_2010}
\citation{rascon_localization_2017}
\citation{brutti_multiple_2010}
\citation{boora_tdoa-based_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Reverberation}{17}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Multiple Sources}{17}{subsection.2.2.4}\protected@file@percent }
\citation{rascon_lightweight_2015}
\citation{hu_estimation_2009}
\citation{rascon_localization_2017}
\citation{argentieri_survey_2015}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Beam-forming}{18}{section.2.3}\protected@file@percent }
\citation{argentieri_survey_2015}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{argentieri_survey_2015}
\citation{rascon_localization_2017}
\citation{badali_evaluating_2009}
\citation{rascon_localization_2017}
\citation{argentieri_survey_2015}
\citation{argentieri_survey_2015}
\citation{valin_localization_2004}
\citation{valin_robust_2003}
\citation{valin_robust_2003}
\citation{valin_robust_2003}
\citation{valin_robust_2007}
\citation{valin_robust_2003}
\citation{valin_robust_2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Literature Examples}{20}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Valin et al., 2004, Localization of Simultaneous Moving Sound Sources for Mobile Robot Using a Frequency- Domain Steered Beamformer Approach}{20}{section*.17}\protected@file@percent }
\citation{valin_robust_2007}
\citation{valin_robust_2007}
\citation{valin_robust_2007}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces The evolution of the search-grid of 2562 points used in \cite  {valin_robust_2003} and in \cite  {valin_robust_2007}\relax }}{21}{figure.caption.18}\protected@file@percent }
\newlabel{fig:valin_2007_grid}{{2.8}{21}{The evolution of the search-grid of 2562 points used in \cite {valin_robust_2003} and in \cite {valin_robust_2007}\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Valin et al., 2007, Robust Localization and Tracking of Simultaneous Moving Sound Sources Using Beamforming and Particle Filtering}{21}{section*.19}\protected@file@percent }
\citation{valin_robust_2007}
\citation{valin_robust_2007}
\citation{badali_evaluating_2009}
\citation{valin_robust_2003}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{valin_robust_2007}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces The two different microphone arrays on the mobile robot, namely C1 on the left and C2 on the right, tested in \cite  {valin_robust_2007}\relax }}{22}{figure.caption.20}\protected@file@percent }
\newlabel{fig:valin_2007_array}{{2.9}{22}{The two different microphone arrays on the mobile robot, namely C1 on the left and C2 on the right, tested in \cite {valin_robust_2007}\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces The estimated azimuth of two tracked sources crossing paths tested in E1 on the left and in E2 on the right in \cite  {valin_robust_2007}\relax }}{22}{figure.caption.21}\protected@file@percent }
\newlabel{fig:valin_2007_track}{{2.10}{22}{The estimated azimuth of two tracked sources crossing paths tested in E1 on the left and in E2 on the right in \cite {valin_robust_2007}\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Badali et al., 2009, Evaluating Real-Time Audio Localization Algorithms for Artificial Audition in Robotics}{22}{section*.22}\protected@file@percent }
\citation{badali_evaluating_2009}
\citation{badali_evaluating_2009}
\citation{badali_evaluating_2009}
\citation{badali_evaluating_2009}
\citation{salvati_power_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces The microphone array tested in \cite  {badali_evaluating_2009}\relax }}{24}{figure.caption.23}\protected@file@percent }
\newlabel{fig:badali_2009_array}{{2.11}{24}{The microphone array tested in \cite {badali_evaluating_2009}\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces The mean angular error as a function of SNR for different methods and configurations in \cite  {badali_evaluating_2009}\relax }}{24}{figure.caption.24}\protected@file@percent }
\newlabel{fig:badali_2009_error_SNR}{{2.12}{24}{The mean angular error as a function of SNR for different methods and configurations in \cite {badali_evaluating_2009}\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{Salvati et al., 2019, Power Method for Robust Diagonal Unloading Localization Beamforming}{24}{section*.25}\protected@file@percent }
\citation{salvati_power_2019}
\citation{salvati_power_2019}
\citation{salvati_power_2019}
\citation{salvati_power_2019}
\citation{zhang_improved_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces The RMS error as a function of SNR for a single source in \cite  {salvati_power_2019}\relax }}{25}{figure.caption.26}\protected@file@percent }
\newlabel{fig:salvati_2019_RMSE_SNR}{{2.13}{25}{The RMS error as a function of SNR for a single source in \cite {salvati_power_2019}\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces The RMS error as a function of SNR for two sources in \cite  {salvati_power_2019}\relax }}{25}{figure.caption.27}\protected@file@percent }
\newlabel{fig:salvati_2019_RMSE_SNR_two}{{2.14}{25}{The RMS error as a function of SNR for two sources in \cite {salvati_power_2019}\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{Zhang et al., 2021, An Improved Multiple Sound Source Localization Method Using a Uniform Concentric Circular Microphone Array}{25}{section*.28}\protected@file@percent }
\citation{zhang_improved_2021}
\citation{zhang_improved_2021}
\citation{basiri_-board_2016}
\citation{brutti_multiple_2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces The energy-maps of various delay-sum-beamformers (DSB) for two sources in \cite  {zhang_improved_2021}\relax }}{26}{figure.caption.29}\protected@file@percent }
\newlabel{fig:zhang_2021_maps}{{2.15}{26}{The energy-maps of various delay-sum-beamformers (DSB) for two sources in \cite {zhang_improved_2021}\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{Basiri et al., 2016, On-Board Relative Bearing Estimation for Teams of Drones Using Sound}{26}{section*.30}\protected@file@percent }
\citation{basiri_-board_2016}
\citation{basiri_-board_2016}
\citation{basiri_-board_2016}
\citation{basiri_-board_2016}
\citation{tamai_three_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces The two different microphone arrays tested in \cite  {basiri_-board_2016}, namely one for the active method (a) and another for the passive method (b),\relax }}{27}{figure.caption.31}\protected@file@percent }
\newlabel{fig:basiri_2016_array}{{2.16}{27}{The two different microphone arrays tested in \cite {basiri_-board_2016}, namely one for the active method (a) and another for the passive method (b),\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces The histogram of the angular error for the passive method in \cite  {basiri_-board_2016}\relax }}{27}{figure.caption.32}\protected@file@percent }
\newlabel{fig:basiri_2016_histogram}{{2.17}{27}{The histogram of the angular error for the passive method in \cite {basiri_-board_2016}\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tamai et al., 2005, Three Ring Microphone Array for 3D Sound Localization and Separation for Mobile Robot Audition}{27}{section*.33}\protected@file@percent }
\citation{mattos_passive_2004}
\citation{tamai_three_2005}
\citation{argentieri_experimental_2005}
\citation{argentieri_prototyping_2005}
\citation{argentieri_modal_2006}
\@writefile{toc}{\contentsline {subsubsection}{Mattos \& Grant, 2004, Passive Sonar Applications: Target Tracking and Navigation of an Autonomous Robot}{28}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Frequency and Width}{28}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}MUSIC}{28}{section.2.4}\protected@file@percent }
\citation{rascon_localization_2017}
\citation{rascon_localization_2017}
\citation{nakamura_real-time_2012}
\citation{rascon_localization_2017}
\citation{ishi_effects_2011}
\citation{nakamura_real-time_2012}
\citation{nakamura_intelligent_2009}
\citation{nakamura_intelligent_2011}
\citation{nakamura_real-time_2012}
\citation{ishi_evaluation_2009}
\citation{brutti_multiple_2010}
\citation{basiri_-board_2016}
\citation{ishi_evaluation_2009}
\citation{ishi_evaluation_2009}
\citation{nakamura_intelligent_2009}
\citation{nakamura_intelligent_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Literature Examples}{30}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Ishi et al., 2009, Evaluation of a MUSIC-Based Real-Time Sound Localization of Multiple Sound Sources in Real Noisy Environments}{30}{section*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces The microphone array on the robot tested in \cite  {ishi_evaluation_2009}\relax }}{30}{figure.caption.36}\protected@file@percent }
\newlabel{fig:ishi_2009_array}{{2.18}{30}{The microphone array on the robot tested in \cite {ishi_evaluation_2009}\relax }{figure.caption.36}{}}
\citation{nakamura_real-time_2012}
\citation{nakamura_real-time_2012}
\citation{nakamura_real-time_2012}
\@writefile{toc}{\contentsline {subsubsection}{Nakamura et al., 2012, Real-Time Super-Resolution Sound Source Localization for Robots}{31}{section*.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces The rate of successful localisations against SNR for SEVD, GEVD, and the proposed GSVD in \cite  {nakamura_real-time_2012}\relax }}{31}{figure.caption.38}\protected@file@percent }
\newlabel{fig:nakamura_2012_rate_SNR}{{2.19}{31}{The rate of successful localisations against SNR for SEVD, GEVD, and the proposed GSVD in \cite {nakamura_real-time_2012}\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Discussion of the Literature}{31}{section.2.5}\protected@file@percent }
\citation{chen_sound_2019}
\citation{bechler_system_2004}
\citation{basiri_-board_2016}
\citation{hu_estimation_2009}
\citation{valin_robust_2003}
\citation{valin_localization_2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Accuracy and Estimation}{32}{subsection.2.5.1}\protected@file@percent }
\citation{manamperi_drone_2022}
\citation{bechler_system_2004}
\citation{basiri_-board_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Dimensions}{33}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Noise and Reverberation}{33}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Computation}{33}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Simulation}{34}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Software}{34}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Python}{34}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Pyroomacoustics}{34}{subsection.3.1.2}\protected@file@percent }
\citation{chen_sound_2019}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\citation{chen_sound_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Sounds}{35}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Evaluation of Examples in the Literature}{35}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Rectangular Pyramid Array with TDOA}{35}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Algorithm}{35}{section*.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The partitions in space of the rectangular pyramid array are used such that an initial condition can be guessed and fed to the iterative algorithm \cite  {chen_sound_2019}.\relax }}{36}{figure.caption.40}\protected@file@percent }
\newlabel{fig:chen_2019_partitions}{{3.1}{36}{The partitions in space of the rectangular pyramid array are used such that an initial condition can be guessed and fed to the iterative algorithm \cite {chen_sound_2019}.\relax }{figure.caption.40}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Guessing the general direction from a rectangular pyramid\relax }}{37}{algorithm.1}\protected@file@percent }
\newlabel{alg:pyramid_guess}{{1}{37}{Guessing the general direction from a rectangular pyramid\relax }{algorithm.1}{}}
\citation{noauthor_handclaps_2005}
\@writefile{toc}{\contentsline {subsubsection}{Experimental Method}{38}{section*.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An example of the RIR made from the Pyroomacoustics module is shown.\relax }}{38}{figure.caption.42}\protected@file@percent }
\newlabel{fig:pyramid_robot_noise_rir}{{3.2}{38}{An example of the RIR made from the Pyroomacoustics module is shown.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance against Noise}{39}{section*.43}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The 3D room is shown and has the rectangular pyramid array in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }}{39}{figure.caption.44}\protected@file@percent }
\newlabel{fig:pyramid_robot_room_3d}{{3.3}{39}{The 3D room is shown and has the rectangular pyramid array in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A bird's-eye-view of the room is shown with the rectangular pyramid array in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }}{40}{figure.caption.45}\protected@file@percent }
\newlabel{fig:pyramid_robot_room_2d}{{3.4}{40}{A bird's-eye-view of the room is shown with the rectangular pyramid array in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The statistical performance of estimated distance is plotted against noise; the red line is the true distance.\relax }}{41}{figure.caption.46}\protected@file@percent }
\newlabel{fig:pyramid_robot_noise_distance}{{3.5}{41}{The statistical performance of estimated distance is plotted against noise; the red line is the true distance.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The statistical performance of estimated azimuth is plotted against noise; the red line is the true azimuth.\relax }}{42}{figure.caption.47}\protected@file@percent }
\newlabel{fig:pyramid_robot_noise_azimuth}{{3.6}{42}{The statistical performance of estimated azimuth is plotted against noise; the red line is the true azimuth.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The statistical performance of estimated elevation is plotted against noise; the red line is the true elevation.\relax }}{43}{figure.caption.48}\protected@file@percent }
\newlabel{fig:pyramid_robot_noise_elevation}{{3.7}{43}{The statistical performance of estimated elevation is plotted against noise; the red line is the true elevation.\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{Performance against Distance}{43}{section*.49}\protected@file@percent }
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{44}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}SRP-PHAT}{44}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Algorithm}{44}{section*.51}\protected@file@percent }
\citation{valin_localization_2004}
\citation{valin_robust_2003}
\citation{valin_localization_2004}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{valin_robust_2007}
\citation{noauthor_handclaps_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The spherical grid of directions was used to estimate the direction of the sound-source using SRP-PHAT.\relax }}{46}{figure.caption.52}\protected@file@percent }
\newlabel{fig:srp_phat_grid}{{3.8}{46}{The spherical grid of directions was used to estimate the direction of the sound-source using SRP-PHAT.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsubsection}{Experimental Method}{46}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stastical Performance against Noise}{47}{section*.54}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The 3D room is shown and has the cubic array for testing the SRP-PHAT method in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }}{47}{figure.caption.55}\protected@file@percent }
\newlabel{fig:srp_phat_room_3d}{{3.9}{47}{The 3D room is shown and has the cubic array for testing the SRP-PHAT method in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces A bird's-eye-view of the room is shown with the cubic array for testing the SRP-PHAT method in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }}{48}{figure.caption.56}\protected@file@percent }
\newlabel{fig:srp_phat_room_2d}{{3.10}{48}{A bird's-eye-view of the room is shown with the cubic array for testing the SRP-PHAT method in the centre 1 \si {m} off the ground and with the source at $(5.5,3,1)$.\relax }{figure.caption.56}{}}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces The statistical performance of the estimated direction is plotted against noise with a clap as the source.\relax }}{49}{figure.caption.57}\protected@file@percent }
\newlabel{fig:srp_phat_noise_clap}{{3.11}{49}{The statistical performance of the estimated direction is plotted against noise with a clap as the source.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces The statistical performance of the estimated direction is plotted against noise with a whistle as the source.\relax }}{49}{figure.caption.58}\protected@file@percent }
\newlabel{fig:srp_phat_noise_whistle}{{3.12}{49}{The statistical performance of the estimated direction is plotted against noise with a whistle as the source.\relax }{figure.caption.58}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualisation of the Energy-Map}{50}{section*.59}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces The energy-map of the SRP-PHAT beamformer is drawn with a clap as the source.\relax }}{51}{figure.caption.60}\protected@file@percent }
\newlabel{fig:srp_phat_noise_map_clap}{{3.13}{51}{The energy-map of the SRP-PHAT beamformer is drawn with a clap as the source.\relax }{figure.caption.60}{}}
\citation{chen_sound_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces The energy-map of the SRP-PHAT beamformer is drawn with a whistle as the source.\relax }}{52}{figure.caption.61}\protected@file@percent }
\newlabel{fig:srp_phat_noise_map_whistle}{{3.14}{52}{The energy-map of the SRP-PHAT beamformer is drawn with a whistle as the source.\relax }{figure.caption.61}{}}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{52}{section*.62}\protected@file@percent }
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\citation{chen_sound_2019}
\citation{valin_localization_2004}
\citation{valin_robust_2007}
\bibstyle{plain}
\bibdata{./zotero}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conclusion}{54}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{noauthor_handclaps_2005}{1}
\bibcite{argentieri_prototyping_2005}{2}
\bibcite{argentieri_experimental_2005}{3}
\bibcite{argentieri_survey_2015}{4}
\bibcite{argentieri_modal_2006}{5}
\bibcite{badali_evaluating_2009}{6}
\bibcite{basiri_-board_2016}{7}
\bibcite{bechler_system_2004}{8}
\bibcite{boora_tdoa-based_2020}{9}
\bibcite{brandstein_robust_1997}{10}
\bibcite{brutti_multiple_2010}{11}
\bibcite{chen_sound_2019}{12}
\bibcite{clifford_calculating_2010}{13}
\bibcite{gustafsson_source_2003}{14}
\bibcite{hu_estimation_2009}{15}
\bibcite{ishi_evaluation_2009}{16}
\bibcite{ishi_effects_2011}{17}
\bibcite{kim_robust_2008}{18}
\bibcite{kwon_analysis_2010}{19}
\bibcite{mahajan_3d_2001}{20}
\bibcite{manamperi_drone_2022}{21}
\bibcite{mattos_passive_2004}{22}
\bibcite{nakamura_intelligent_2009}{23}
\bibcite{nakamura_intelligent_2011}{24}
\bibcite{nakamura_real-time_2012}{25}
\bibcite{rascon_lightweight_2015}{26}
\bibcite{rascon_localization_2017}{27}
\bibcite{sakavicius_multiple_2022}{28}
\bibcite{salvati_power_2019}{29}
\bibcite{tamai_three_2005}{30}
\bibcite{valin_localization_2004}{31}
\bibcite{valin_robust_2003}{32}
\bibcite{valin_robust_2007}{33}
\bibcite{zhang_improved_2021}{34}
\gdef \@abspage@last{58}
