
@article{rascon_localization_2017,
	title = {Localization of sound sources in robotics: {A} review},
	volume = {96},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889016304742},
	doi = {https://doi.org/10.1016/j.robot.2017.07.011},
	abstract = {Sound source localization (SSL) in a robotic platform has been essential in the overall scheme of robot audition. It allows a robot to locate a sound source by sound alone. It has an important impact on other robot audition modules, such as source separation, and it enriches human–robot interaction by complementing the robot’s perceptual capabilities. The main objective of this review is to thoroughly map the current state of the SSL field for the reader and provide a starting point to SSL in robotics. To this effect, we present: the evolution and historical context of SSL in robotics; an extensive review and classification of SSL techniques and popular tracking methodologies; different facets of SSL as well as its state-of-the-art; evaluation methodologies used for SSL; and a set of challenges and research motivations.},
	journal = {Robotics and Autonomous Systems},
	author = {Rascon, Caleb and Meza, Ivan},
	year = {2017},
	keywords = {Direction-of-arrival, Distance estimation, Robot audition, Sound source localization, Tracking},
	pages = {184--210},
}

@article{argentieri_survey_2015,
	title = {A survey on sound source localization in robotics: {From} binaural to array processing methods},
	volume = {34},
	issn = {0885-2308},
	url = {https://www.sciencedirect.com/science/article/pii/S0885230815000236},
	doi = {https://doi.org/10.1016/j.csl.2015.03.003},
	abstract = {This paper attempts to provide a state-of-the-art of sound source localization in robotics. Noticeably, this context raises original constraints—e.g. embeddability, real time, broadband environments, noise and reverberation—which are seldom simultaneously taken into account in acoustics or signal processing. A comprehensive review is proposed of recent robotics achievements, be they binaural or rooted in array processing techniques. The connections are highlighted with the underlying theory as well as with elements of physiology and neurology of human hearing.},
	number = {1},
	journal = {Computer Speech \& Language},
	author = {Argentieri, S. and Danès, P. and Souères, P.},
	year = {2015},
	keywords = {Robot audition, Array processing, Binaural audition, Source localization},
	pages = {87--112},
}

@inproceedings{badali_evaluating_2009,
	title = {Evaluating real-time audio localization algorithms for artificial audition in robotics},
	doi = {10.1109/IROS.2009.5354308},
	abstract = {Although research on localization of sound sources using microphone arrays has been carried out for years, providing such capabilities on robots is rather new. Artificial audition systems on robots currently exist, but no evaluation of the methods used to localize sound sources has yet been conducted. This paper presents an evaluation of various real-time audio localization algorithms using a medium-sized microphone array which is suitable for applications in robotics. The techniques studied here are implementations and enhancements of steered response power - phase transform beamformers, which represent the most popular methods for time difference of arrival audio localization. In addition, two different grid topologies for implementing source direction search are also compared. Results show that a direction refinement procedure can be used to improve localization accuracy and that more efficient and accurate direction searches can be performed using a uniform triangular element grid rather than the typical rectangular element grid.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Badali, Anthony and Valin, Jean-Marc and Michaud, François and Aarabi, Parham},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0866},
	pages = {2033--2038},
}

@inproceedings{valin_localization_2004,
	title = {Localization of simultaneous moving sound sources for mobile robot using a frequency- domain steered beamformer approach},
	volume = {1},
	doi = {10.1109/ROBOT.2004.1307286},
	abstract = {Mobile robots in real-life settings would benefit from being able to localize sound sources. Such a capability can nicely complement vision to help localize a person or an interesting event in the environment, and also to provide enhanced processing for other capabilities such as speech recognition. We present a robust sound source localization method in three-dimensional space using an array of 8 microphones. The method is based on a frequency-domain implementation of a steered beamformer along with a probabilistic post-processor. Results show that a mobile robot can localize in real time multiple moving sources of different types over a range of 5 meters with a response time of 200 ms.},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}, 2004. {Proceedings}. {ICRA} '04. 2004},
	author = {Valin, J.-M. and Michaud, F. and Hadjou, B. and Rouat, J.},
	month = apr,
	year = {2004},
	note = {ISSN: 1050-4729},
	pages = {1033--1038 Vol.1},
}

@inproceedings{tamai_three_2005,
	title = {Three ring microphone array for {3D} sound localization and separation for mobile robot audition},
	doi = {10.1109/IROS.2005.1545095},
	abstract = {This paper describes a three ring microphone array estimates the horizontal/vertical direction and distance of sound sources and separates multiple sound sources for mobile robot audition. Arrangement of microphones is simulated and an optimized pattern which has three rings is implemented with 32 microphones. Sound localization and separation are achieved by delay and sum beam forming (DSBF) and frequency band selection (FBS). From on-line experiments results of sound horizontal and vertical localization, we confirmed that one or two sounds sources could be localized with an error of about 5 degrees and 200 to 300 mm in the case of the distance of about lm. The off-line experiments of sound separation were evaluated by power spectrums in each frequency of separated sounds, and we confirmed that an appropriate frequency band could be selected by DSBF and FBS. The system can separate 3 different pressure speech sources without drowning out.},
	booktitle = {2005 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Tamai, Y. and Sasaki, Y. and Kagami, S. and Mizoguchi, H.},
	month = aug,
	year = {2005},
	note = {ISSN: 2153-0866},
	pages = {4172--4177},
}

@inproceedings{mattos_passive_2004,
	title = {Passive sonar applications: target tracking and navigation of an autonomous robot},
	volume = {5},
	doi = {10.1109/ROBOT.2004.1302388},
	abstract = {This paper demonstrates the use of small area acoustic array technology as passive sonar for an autonomous mobile robot sound localization and direction control. Real-time target tracking is based solely on received audio signals.},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}, 2004. {Proceedings}. {ICRA} '04. 2004},
	author = {Mattos, L. and Grant, E.},
	month = apr,
	year = {2004},
	note = {ISSN: 1050-4729},
	pages = {4265--4270 Vol.5},
}

@inproceedings{argentieri_prototyping_2005,
	title = {Prototyping {Filter}-{Sum} {Beamformers} for {Sound} {Source} {Localization} in {Mobile} {Robotics}},
	doi = {10.1109/ROBOT.2005.1570660},
	abstract = {The work presented in this paper comes as a part of a project which aims at developing an auditory system for a mobile robot. It presents a sound source localization strategy which enables the sensing of signals within a direction of arrival and frequency domain of interest while rejecting other data. A rapid prototyping method is proposed to design filter-sum beamformers on the basis of convex optimization. This method is well-suited to robotics applications as it copes with real-time constraints and allows the localization of broadband signals such as human voice. Numerous simulation results are used to illustrate the reasoning.},
	booktitle = {Proceedings of the 2005 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Argentieri, S. and Danes, P. and Soueres, P.},
	month = apr,
	year = {2005},
	note = {ISSN: 1050-4729},
	pages = {3551--3556},
}

@inproceedings{argentieri_experimental_2005,
	title = {An experimental testbed for sound source localization with mobile robots using optimized wideband beamformers},
	doi = {10.1109/IROS.2005.1545096},
	abstract = {This paper addresses the problem of practically implementing an original sound source localization strategy for mobile robots applications. The proposed method is based on a convex optimization solution to beamforming. It allows the sensing of signals within a direction of arrival and frequency domain of interest while rejecting other data. A precise description of the acquisition chain is proposed and a careful mathematical modeling is given in order to bridge the gap between theory and practical implementation. Simulation results and comparisons with classical filter-sum beamformer techniques are provided at the end of the paper to illustrate the performance of the sensor.},
	booktitle = {2005 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Argentieri, S. and Danes, P. and Soueres, P. and Lacroix, P.},
	month = aug,
	year = {2005},
	note = {ISSN: 2153-0866},
	pages = {2536--2541},
}

@inproceedings{argentieri_modal_2006,
	title = {Modal {Analysis} {Based} {Beamforming} for {Nearfield} or {Farfield} {Speaker} {Localization} in {Robotics}},
	doi = {10.1109/IROS.2006.281739},
	abstract = {This paper describes a broadband beampattern synthesis method for sound source localization in the nearfield or in the farfield of a mobile robot, with a small-size linear array. The method is based on the theory of modal analysis and involves an original convex optimization procedure which benefits from the Parseval relation. The optimized beampattern is obtained by numerically minimizing the worst-case error between the modal coefficients of the array response and those of the reference beampattern, up to a finite rank of the series expansion, over a frequency grid. Simulations illustrate the analytical development},
	booktitle = {2006 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Argentieri, Sylvain and Danes, Patrick and Soueres, Philippe},
	month = oct,
	year = {2006},
	note = {ISSN: 2153-0866},
	pages = {866--871},
}

@article{valin_robust_2007,
	title = {Robust {Localization} and {Tracking} of {Simultaneous} {Moving} {Sound} {Sources} {Using} {Beamforming} and {Particle} {Filtering}},
	volume = {55},
	doi = {10.1016/j.robot.2006.08.004},
	journal = {Robotics and Autonomous Systems},
	author = {Valin, Jean-Marc and Michaud, François and Rouat, Jean},
	month = mar,
	year = {2007},
	pages = {216--228},
}

@inproceedings{valin_robust_2003,
	title = {Robust sound source localization using a microphone array on a mobile robot},
	volume = {2},
	doi = {10.1109/IROS.2003.1248813},
	abstract = {The hearing sense on a mobile robot is important because it is omnidirectional and it does not require direct line-of-sight with the sound source. Such capabilities can nicely complement vision to help localize a person or an interesting event in the environment. To do so the robot auditory system must be able to work in noisy, unknown and diverse environmental conditions. In this paper, we present a robust sound source localization method in three-dimensional space using an array of 8 microphones. The method is based on time delay of arrival estimation. Results show that a mobile robot can localize in real time different types of sound sources over a range of 3 meters and with a precision of 3/spl deg/.},
	booktitle = {Proceedings 2003 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS} 2003) ({Cat}. {No}.{03CH37453})},
	author = {Valin, J.-M. and Michaud, F. and Rouat, J. and Letourneau, D.},
	month = oct,
	year = {2003},
	pages = {1228--1233 vol.2},
}

@inproceedings{hu_estimation_2009,
	title = {Estimation of sound source number and directions under a multi-source environment},
	doi = {10.1109/IROS.2009.5354706},
	abstract = {Sound source localization is an important feature in robot audition. This work proposes a sound source number and directions estimation method by using the delay information of microphone array. An eigenstructure-based generalized cross correlation method is proposed to estimate time delay between microphones. Upon obtaining the time delay information, the sound source direction and velocity can be estimated by least square method. In multiple sound source case, the time delay combination among microphones is arranged such that the estimated sound speed value falls within an acceptable range. By accumulating the estimation results of sound source direction and using adaptive K-means++ algorithm, the sound source number and directions can be estimated.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Hu, Jwu-Sheng and Yang, Chia-Hsing and Wang, Cheng-Kang},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0866},
	pages = {181--186},
}

@article{chen_sound_2019,
	title = {A {Sound} {Source} {Localization} {Device} {Based} on {Rectangular} {Pyramid} {Structure} for {Mobile} {Robot}},
	volume = {2019},
	doi = {10.1155/2019/4639850},
	abstract = {A sound source localization device based on a multimicrophone array with the rectangular pyramid structure is proposed for mobile robot in some indoor applications. Firstly, a time delay estimation method based on the cross-power spectral phase algorithm and a fast search strategy of peak value based on the geometric distribution of microphones are developed to estimate the sound propagation delay differences between two microphones. Moreover, a rejection strategy is presented to evaluate the correctness of the delay difference values. And then, the device’s geometric equations based on the time-space mapping relationship are established to calculate the position of the sound source. For fast solving the equations, the multimicrophone array space is divided into several subspaces to narrow the solution range, and Newton iteration algorithm is introduced to solve the equations, while its solution is evaluated by an evaluation mechanism based on coordinate thresholds. Finally, some experiments are carried out to verify the performance of the device, of which the results show that the device can achieve sound source localization with a high accuracy.},
	journal = {Journal of Sensors},
	author = {Chen, Guoliang and Xu, Yang},
	month = aug,
	year = {2019},
	pages = {1--13},
}

@inproceedings{bechler_system_2004,
	title = {System for robust {3D} speaker tracking using microphone array measurements},
	volume = {3},
	doi = {10.1109/IROS.2004.1389722},
	abstract = {A system for three-dimensional passive acoustic speaker localization and tracking using a microphone array is presented and evaluated. Initial speaker position estimates are provided by a time-delay-based localization algorithm. These raw estimates are spatially smoothed by a multiple model adaptive estimator consisting of three extended Kalman filters running in parallel. The performance of the proposed system is evaluated for real data in a common office environment. The reference trajectory of the moving speaker is delivered by visually tracking a color marker on the speaker's forehead by a stereo-camera system. The proposed acoustic source tracker shows robustness and accuracy in a variety of different scenarios.},
	booktitle = {2004 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS}) ({IEEE} {Cat}. {No}.{04CH37566})},
	author = {Bechler, D. and Schlosser, M.S. and Kroschel, K.},
	month = sep,
	year = {2004},
	pages = {2117--2122 vol.3},
}

@inproceedings{kim_robust_2008,
	title = {Robust estimation of sound direction for robot interface},
	doi = {10.1109/ROBOT.2008.4543742},
	abstract = {This paper proposes a robust method to estimate sound direction for mobile robot interface. In contrast to other methods, the proposed method estimates sound direction at intervals of short time to deal with deterioration by movement of sound source or robot. The two methods, discrete Kalman filter and time delay of arrival (TDOA) using generalized cross-correlation (GCC), are combined by quantifying reliability of TDOA. The combination prevents the deterioration by low power of signals, noise, and reverberation because discrete Kalman filter efficiently filters out such effects. The result of experiments, in which mobile robot estimates azimuth angle with three microphones, shows that the proposed method provides robustness on estimating sound direction even if the sound source or robot is moving during estimation procedure.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kim, Cheol-Taek and Choi, Tae-Yong and Choi, ByongSuk and Lee, Ju-Jang},
	month = may,
	year = {2008},
	note = {ISSN: 1050-4729},
	pages = {3475--3480},
}

@article{mahajan_3d_2001,
	title = {{3D} position sensing using the differences in the time-of-flights from a wave source to various receivers},
	volume = {17},
	issn = {2374-958X},
	doi = {10.1109/70.917087},
	abstract = {This paper presents a novel formulation for the estimation of the coordinates of a wave source based on the differences in the time-of-flights from a single transmitter to various receivers fixed in 3D space. The formulation is closed form linear, and estimates the speed of sound at every ranging operation. This leads to a robust system that is insensitive to changes in the environmental conditions. Typical applications that will benefit from this technology are 3D position sensing systems that may be used in robotics, navigation of autonomously guided vehicles, tracking of objects for virtual reality cells, and vibration analysis.},
	number = {1},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Mahajan, A. and Walworth, M.},
	month = feb,
	year = {2001},
	pages = {91--94},
}

@article{gustafsson_source_2003,
	title = {Source localization in reverberant environments: modeling and statistical analysis},
	volume = {11},
	issn = {1558-2353},
	doi = {10.1109/TSA.2003.818027},
	abstract = {Room reverberation is typically the main obstacle for designing robust microphone-based source localization systems. The purpose of the paper is to analyze the achievable performance of acoustical source localization methods when room reverberation is present. To facilitate the analysis, we apply well known results from room acoustics to develop a simple but useful statistical model for the room transfer function. The properties of the statistical model are found to correlate well with results from real data measurements. The room transfer function model is further applied to analyze the statistical properties of some existing methods for source localization. In this respect we consider especially the asymptotic error variance and the probability of an anomalous estimate. A noteworthy outcome of the analysis is that the so-called PHAT time-delay estimator is shown to be optimal among a class of cross-correlation based time-delay estimators. To verify our results on the error variance and the outlier probability we apply the image method for simulation of the room transfer function.},
	number = {6},
	journal = {IEEE Transactions on Speech and Audio Processing},
	author = {Gustafsson, T. and Rao, B.D. and Trivedi, M.},
	month = nov,
	year = {2003},
	pages = {791--803},
}

@inproceedings{brandstein_robust_1997,
	title = {A robust method for speech signal time-delay estimation in reverberant rooms},
	volume = {1},
	doi = {10.1109/ICASSP.1997.599651},
	abstract = {Conventional time-delay estimators exhibit dramatic performance degradations in the presence of multipath signals. This limits their application in reverberant enclosures, particularly when the signal of interest is speech and it may not possible to estimate and compensate for channel effects prior to time-delay estimation. This paper details an alternative approach which reformulates the problem as a linear regression of phase data and then estimates the time-delay through minimization of a robust statistical error measure. The technique is shown to be less susceptible to room reverberation effects. Simulations are performed across a range of source placements and room conditions to illustrate the utility of the proposed time-delay estimation method relative to conventional methods.},
	booktitle = {1997 {IEEE} {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing}},
	author = {Brandstein, M.S. and Silverman, H.F.},
	month = apr,
	year = {1997},
	note = {ISSN: 1520-6149},
	pages = {375--378 vol.1},
}

@article{clifford_calculating_2010,
	title = {calculating time delays of multiple active sources in live sound},
	abstract = {delays caused by differences in distance between sources and microphones cause many problems in live audio, most notably comb filtering. this paper presents a new method that is able to calculate the relative time delays of multiple active sources to multiple microphones where previous methods are unable to. the calculated time delays can be used to compensate for delays that cause comb filtering and can also be used in source separation methods which utilise delays. the proposed method is shown to be able to calculate delays in configurations where other methods fail and is also able to give an estimate of sources physical positions. the results show that multiple delays can be accurately calculated when multiple sources are active and that noise can effect the accuracy of the method.},
	journal = {journal of the audio engineering society},
	author = {clifford, alice and reiss, joshua},
	month = nov,
	year = {2010},
}

@inproceedings{kwon_analysis_2010,
	title = {Analysis of the {GCC}-{PHAT} technique for multiple sources},
	doi = {10.1109/ICCAS.2010.5670137},
	booktitle = {{ICCAS} 2010},
	author = {Kwon, Byoungho and Park, Youngjin and Park, Youn-sik},
	year = {2010},
	pages = {2070--2073},
}

@inproceedings{dey_design_2019,
	title = {Design of a {Real}-{Time} {Automatic} {Source} {Monitoring} {Framework} {Based} on {Sound} {Source} {Localization}},
	doi = {10.1109/ICDIPC.2019.8723684},
	abstract = {Sound Source Localization is the technique to exactly locate the position of a sound emitting source with the help of the audio data only. Its applications are audio surveillance, security monitoring where visual data is not available, robotics such as robots acting as a waiter, etc. It is also an initial stage of signal processing for the fields of speech enhancement, speech separation and Automatic Speech Recognition (ASR). Localization is usually carried out using array of microphones. The scenario of locating a sound source can be different such as single source localization, multiple source localization, moving source localization, source localization in noisy environment, etc. Extensive research progress is there in this field due to its multidimensional applications. This paper attempts to address some of the existing challenges in this field. Work in this paper deals with designing of a real-time, automatic target monitoring framework based on sound source localization. A comparative study of our results with other standard localization algorithm is also presented. The studies presented in this paper leads to the fact that the designed sound source localization framework is indeed low cost, small, real-time and able to locate multiple sources satisfactorily even in office environment where level of noise and reverberation is higher than standard anechoic rooms.},
	booktitle = {2019 {Seventh} {International} {Conference} on {Digital} {Information} {Processing} and {Communications} ({ICDIPC})},
	author = {Dey, Spandan and Boppu, Srinivas and Manikandan, M. Sabarimalai},
	month = may,
	year = {2019},
	pages = {35--40},
}

@article{sakavicius_multiple_2022,
	title = {Multiple {Sound} {Source} {Localization} in {Three} {Dimensions} {Using} {Convolutional} {Neural} {Networks} and {Clustering} {Based} {Post}-{Processing}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3225968},
	abstract = {Sound source localization methods are successfully applied for various estimation tasks, such as tracking and detecting objects, aiming cameras, and navigating robots. However, large and usually complex distributed microphone arrays are used for three-dimensional acoustic source localization. This study proposes a convolutional neural network architecture for three-dimensional sound source localization using a single tetrahedral microphone array. A spectrum phase component of a microphone array signal was designed as the input of the model, while the output represents a three-dimensional space. The paper provides extensive experimental results of the given method on a semi-synthetic audio data set and a real-world microphone array. Furthermore, cluster-based post-processing has been shown to increase the accuracy of three-dimensional localization by more than 30\%. The experimental results on a synthesized data set using the image source method showed 1.08 m localization uncertainties. The estimate of the investigated sound sources had a mean absolute error of 18.97° and elevation error of 48.49°. An additional advantage of the proposed method is the ability to predict the location of the sound source from a single signal analysis frame. This gives instant localization and is in line with many alternative applications. The proposed solution does not require intensive preprocessing of the audio signals and can be used as a video camera pointing system based on a microphone array. In the future, it would be relevant to investigate the localization performance of more than two sound sources, and the variable acoustic conditions could also be assessed.},
	journal = {IEEE Access},
	author = {Sakavičius, Saulius and Serackis, Artūras and Abromavičius, Vytautas},
	year = {2022},
	pages = {125707--125722},
}

@article{boora_tdoa-based_2020,
	title = {A {TDOA}-based multiple source localization using delay density maps},
	volume = {45},
	issn = {0973-7677},
	url = {https://doi.org/10.1007/s12046-020-01453-8},
	doi = {10.1007/s12046-020-01453-8},
	abstract = {The higher computational efficiency of the time difference of arrival (TDOA) based sound source localization makes it a preferred choice over steered response power (SRP) methods in real-time applications. However, unlike SRP, its implementation for multiple source localization (MSL) is not straight forward. It includes challenges as accurate feature extraction in unfavourable acoustic conditions, association ambiguity involved in mapping the feature extractions to the corresponding sources and complexity involved in solving the hyperbolic delay equation to estimate the source coordinates. Moreover, the dominating source and early reverberation make the detection of delay associated with the submissive sources further perplexing. Hence, this paper proposes a proficient three-step method for localizing multiple sources from delay estimates. In step 1, the search space region is partitioned into cubic subvolumes, and the delay bound associated with each one is computed. Hereafter, these subvolumes are grouped differently, such that whose associated TDOA bounds are enclosed by a specific delay interval, are clustered together. In step 2, initially, the delay segments and later each subvolume contained by the corresponding delay segment are traced for passing through estimated delay hyperbola. These traced volumes are updated by the weight to measure the likelihood of a source in it. The resultant generates the delay density map in the search space. In the final step, localization enhancement is carried out in the selected volumes using conventional SRP (C-SRP). The validation of the proposed approach is done by carrying out the experiments under different acoustic conditions on the synthesized data and, recordings from SMARD \& Audio Visual 16.3 Corpus.},
	number = {1},
	journal = {Sādhanā},
	author = {Boora, Ritu and Dhull, Sanjeev Kumar},
	month = aug,
	year = {2020},
	pages = {204},
}

@article{brutti_multiple_2010,
	title = {Multiple source localization based on acoustic map de-emphasis},
	volume = {2010},
	journal = {EURASIP Journal on Audio, Speech, and Music Processing},
	author = {Brutti, Alessio and Omologo, Maurizio and Svaizer, Piergiorgio},
	year = {2010},
	note = {Publisher: Springer},
	pages = {1--17},
}

@article{rascon_lightweight_2015,
	title = {Lightweight multi-{DOA} tracking of mobile speech sources},
	volume = {2015},
	doi = {10.1186/s13636-015-0055-8},
	journal = {EURASIP Journal on Audio, Speech, and Music Processing},
	author = {Rascon, Caleb and Fuentes-Pineda, Gibran and Meza, Ivan},
	month = dec,
	year = {2015},
}

@article{lim_speaker_2015,
	title = {Speaker localization in noisy environments using steered response voice power},
	volume = {61},
	issn = {1558-4127},
	doi = {10.1109/TCE.2015.7064118},
	abstract = {Many devices, including smart TVs and humanoid robots, can be operated through speech interface. Since a user can interact with such a device at a distance, speech-operated devices must be able to process speech signals from a distance. Although many methods exist to localize speakers via sound source localization, it is very difficult to reliably find the location of a speaker in a noisy environment. In particular, conventional sound source localization methods only find the loudest sound source within a given area, and such a sound source may not necessarily be related to human speech. This can be problematic in real environments where loud noises frequently occur, and the performance of speech-based interfaces for a variety of devices could be negatively impacted as a result. In this paper, a new speaker localization method is proposed. It identifies the location associated with the maximum voice power from all candidate locations. The proposed method is tested under a variety of conditions using both simulation data and real data, and the results indicate that the performance of the proposed method is superior to that of a conventional algorithm for various types of noises1.},
	number = {1},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Lim, Hyeontaek and Yoo, In-Chul and Cho, Youngkyu and Yook, Dongsuk},
	month = feb,
	year = {2015},
	pages = {112--118},
}

@inproceedings{gamboa-montero_real-time_2022,
	title = {Real-{Time} {Acoustic} {Touch} {Localization} in {Human}-{Robot} {Interaction} based on {Steered} {Response} {Power}},
	doi = {10.1109/ICDL53763.2022.9962225},
	abstract = {The sense of touch plays an important role in Human-Robot Interaction, allowing a natural form of communication with humans and improving the rest of the robot’s senses. This is even more important in the subject of social robotics, where robots must interact with people and adhere to social conventions while doing so. Touch interfaces can be implemented as part of a robotic platform serving multiple purposes. Some examples include the use of tactile commands to control the movement of a robot, or attempting to endow a robot with the ability to understand human emotional states. This work proposes a system to localize a contact performed on the rigid, non-planar shell of a service robot in real-time, based on set of spatially separated piezo transducers attached to the shell of the robot and the Steered Response Power sound source localization algorithm. Results show the potential capability of the system to correctly detect and localize human touches.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Development} and {Learning} ({ICDL})},
	author = {Gamboa-Montero, Juan José and Basiri, Meysam and Castillo, José Carlos and Marques-Villarroya, Sara and Salichs, Miguel Angel},
	month = sep,
	year = {2022},
	pages = {101--106},
}

@article{basiri_-board_2016,
	title = {On-{Board} {Relative} {Bearing} {Estimation} for {Teams} of {Drones} {Using} {Sound}},
	volume = {1},
	issn = {2377-3766},
	doi = {10.1109/LRA.2016.2527833},
	abstract = {In a team of autonomous drones, individual knowledge about the relative location of teammates is essential. Existing relative positioning solutions for teams of small drones mostly rely on external systems such as motion tracking cameras or GPS satellites that might not always be accessible. In this letter, we describe an onboard solution to measure the 3-D relative direction between drones using sound as the main source of information. First, we describe a method to measure the directions of other robots from perceiving their engine sounds in the absence of self-engine noise. We then extend the method to use active acoustic signaling to obtain the relative directions in the presence of self-engine noise, to increase the detection range, and to discriminate the identity of robots. Methods are evaluated in real world experiments and a fully autonomous leader-following behavior is illustrated with two drones using the proposed system.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Basiri, Meysam and Schill, Felix and Lima, Pedro and Floreano, Dario},
	month = jul,
	year = {2016},
	pages = {820--827},
}

@inproceedings{zhang_improved_2021,
	title = {An {Improved} {Multiple} {Sound} {Source} {Localization} {Method} {Using} a {Uniform} {Concentric} {Circular} {Microphone} {Array}},
	doi = {10.1109/ICICIP53388.2021.9642218},
	abstract = {Sound source localization finds its applications in various scenarios, such as video conferences, human-robot interaction, intelligent robotics, transportation, fault detection and medical treatment. To overcome the conflict of low frequency resolution issue for the microphone array with small aperture and spatial aliasing issue caused by the microphone array with large aperture, this paper adopts a uniform concentric circular array topology and proposes an improved method based on delay and sum beamforming algorithm to realize the multiple sound sources localization. Experimental results illustrate the effectiveness of the proposed algorithm.},
	booktitle = {2021 11th {International} {Conference} on {Intelligent} {Control} and {Information} {Processing} ({ICICIP})},
	author = {Zhang, Yuting and Zhang, Hongwei and Liu, Honghai},
	month = dec,
	year = {2021},
	pages = {392--397},
}

@article{chen_broadband_2022,
	title = {Broadband {Sound} {Source} {Localisation} via {Non}-{Synchronous} {Measurements} for {Service} {Robots}: {A} {Tensor} {Completion} {Approach}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2022.3212665},
	abstract = {Constraint by the physical geometry, the lower and upper frequency bound and the scale of the scanning area of a microphone array are limited. Owing to its movable feature, for the service robots, achieving a wider working frequency range with a global view requires a virtually larger and denser array, which can be realised using non-synchronous measurements beamforming with a movable microphone array prototype. However, even when using the state-of-the-art method, it is challenging to localise multiple broadband sources, owing to the difficulty in selecting an appropriate operating frequency without any prior information about the target signal. Therefore, this letter proposes a tensor-completion-based non-synchronous measurements method for broadband multiple-sound-source localisation. The tensor data structure of the broadband signal is analysed, and an alternating direction method based on multiplier optimisation with a tensor multi-norm constraint is proposed. This algorithm can provide a sound map with a distinct global view of three different speech signal sources with high accuracy. Compared with the matrix-based optimisation method, the proposed method can significantly reduce the mean square error of the estimated source location.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Chen, Long and Sun, Weize and Huang, Lei and Yu, Liang},
	month = oct,
	year = {2022},
	pages = {12193--12200},
}

@inproceedings{chen_large_2022,
	title = {A {Large} {Scale} {3D} {Sound} {Source} {Localisation} {Approach} {Achieved} via {Small} {Size} {Microphone} {Array} for {Service} {Robots}},
	doi = {10.1109/ICICSP55539.2022.10050648},
	abstract = {Ahstract-The working frequency range and the scale of the scanning area of a microphone array are typically limited by the array geometry. Owing to its movable feature, for the service robots, achieving a wider working frequency range with a 3-dimension global view requires a virtually larger and denser 3-dimension array, which can be realised by using non-synchronous measurements beamforming with a movable microphone prototype array. However, even when using the state-of-the-art method, it is challenging to localise multiple broadband sources, owing to the difficulty in selecting an appropriate operating frequency without any prior information about the target signal. Therefore, this paper proposes a tensor-completion-based non-synchronous measurement method for broadband multiple-sound-source localisation. The tensor data structure of the broadband signal is analysed, and an alternating direction method based on multiplier optimisation with a tensor multi-norm constraint is proposed. This algorithm can provide a sound map with a distinct 3-dimension global view of different speech signal sources with high accuracy via a 16-channel planar microphone array. Compared with the matrix-based optimisation method, the proposed method can significantly reduce the mean square error of the estimated source location.},
	booktitle = {2022 5th {International} {Conference} on {Information} {Communication} and {Signal} {Processing} ({ICICSP})},
	author = {Chen, Long and Huang, Lei and Chen, Guitong and Sun, Weize},
	month = nov,
	year = {2022},
	note = {ISSN: 2770-792X},
	pages = {589--594},
}

@inproceedings{kallakuri_probabilistic_2013,
	title = {Probabilistic approach for building auditory maps with a mobile microphone array},
	doi = {10.1109/ICRA.2013.6630884},
	abstract = {This paper presents a multi-modal sensor approach for mapping sound sources using an omni-directional microphone array on an autonomous mobile robot. A fusion of audio data (from the microphone array), odometry information and the laser range scan data (from the robot) was used to precisely localize and map the audio sources in an environment. An audio map is created while the robot is autonomously navigating through the environment by continuously generating audio scans with a steered response power (SRP) algorithm. Using the poses of the robot, rays are cast in the map in all directions given by the SRP. Then each occupied cell in the geometric map hit by a ray is assigned a likelihood of containing a sound source. This likelihood is derived from the SRP at that particular instant. Since the localization of the robot is probabilistic, the uncertainty in the pose of the robot in the geometric map is propagated to the occupied cells hit during the ray casting. This process is repeated while the robot is in motion and the map is updated after every audio scan. The generated sound maps were reused and the changes in the audio environment were updated by the robot as it identifies these changes.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kallakuri, Nagasrikanth and Even, Jani and Morales, Yoichi and Ishi, Carlos and Hagita, Norihiro},
	month = may,
	year = {2013},
	note = {ISSN: 1050-4729},
	pages = {2270--2275},
}

@inproceedings{veiback_sound_2020,
	title = {Sound {Source} {Localization} and {Reconstruction} {Using} a {Wearable} {Microphone} {Array} and {Inertial} {Sensors}},
	doi = {10.23919/FUSION45008.2020.9190480},
	abstract = {A wearable microphone array platform is used to localize stationary sound sources and amplify the sound in the desired directions using several beamforming methods. The platform is equipped with inertial sensors and a magnetometer allowing predictions of source locations during orientation changes and compensation for the displacement in the array configuration. The platform is modular, open and 3D printed to allow for easy reconfiguration of the array and for reuse in other applications, e.g., mobile robotics. The software components are based on open source. A new method for source localization and signal reconstruction using Taylor expansion of the signals is proposed. This and various standard and non-standard Direction of Arrival (DOA) methods are evaluated in simulation and experiments with the platform to track and reconstruct multiple and single sources. Results show that sound sources can be localized and tracked robustly and accurately while rotating the platform and that the proposed method outperforms standard methods at reconstructing the signals.},
	booktitle = {2020 {IEEE} 23rd {International} {Conference} on {Information} {Fusion} ({FUSION})},
	author = {Veibäck, Clas and Skoglund, Martin A. and Gustafsson, Fredrik and Hendeby, Gustaf},
	month = jul,
	year = {2020},
	pages = {1--8},
}

@inproceedings{tourbabin_speaker_2014,
	title = {Speaker localization by humanoid robots in reverberant environments},
	doi = {10.1109/EEEI.2014.7005877},
	abstract = {One of the important tasks of a humanoid-robot auditory system is speaker localization. It is used for the construction of the surrounding acoustic scene and as an input for additional processing methods. Localization is usually required to operate indoors under high reverberation levels. Recently, an algorithm for speaker localization under these conditions was proposed. The algorithm uses a spherical microphone array and the processing is performed in the spherical harmonics domain, requiring a relatively large number of microphones to efficiently cover the entire frequency range of speech. However, the number of microphones in the auditory system of a humanoid robot is usually limited. The current paper proposes an improvement of the previously published algorithm. The improvement aims to overcome the frequency limitations imposed by the insufficient number of microphones. The improvement is achieved by using a novel space-domain distance algorithm that does not requires the transformation to the spherical harmonics domain, thereby avoiding the frequency range limitations. A numerical study shows two important results. The first is that, using the improved algorithm, the operation frequency range can be significantly extended. The second important result is related to the fact that higher frequencies contain more detailed information about the surrounding sound field. Hence, the additional higher frequencies lead to improved localization accuracy.},
	booktitle = {2014 {IEEE} 28th {Convention} of {Electrical} \& {Electronics} {Engineers} in {Israel} ({IEEEI})},
	author = {Tourbabin, Vladimir and Rafaely, Boaz},
	month = dec,
	year = {2014},
	pages = {1--5},
}

@article{salvati_power_2019,
	title = {Power {Method} for {Robust} {Diagonal} {Unloading} {Localization} {Beamforming}},
	volume = {26},
	issn = {1558-2361},
	doi = {10.1109/LSP.2019.2908245},
	abstract = {We propose a robust version of the diagonal unloading (DU) beamforming for the acoustic source localization problem in high noise conditions. The DU beamformer exploits the subspace orthogonality property by the removal or the attenuation of the signal subspaces, obtained through the subtraction of an opportune diagonal matrix from the covariance matrix. As a result, it provides high-resolution directional response with low computational complexity. We show that a robust DU beamformer can be implemented by subtracting the largest eigenvalue of the estimated covariance matrix from the diagonal elements, and that this implementation is valid in general (i.e., for both the single-source and the multiple-source case). We propose the use of the power method for the estimation of the largest eigenvalue in the DU procedure. We show with numerical simulations that the proposed method improves the localization performance in high noise conditions without substantial increment of the computational cost. Applications for this method include a number of scenarios involving multirotor aerial systems due to its robustness to the noise and its low computational complexity.},
	number = {5},
	journal = {IEEE Signal Processing Letters},
	author = {Salvati, Daniele and Drioli, Carlo and Foresti, Gian Luca},
	month = may,
	year = {2019},
	pages = {725--729},
}

@article{manamperi_drone_2022,
	title = {Drone {Audition}: {Sound} {Source} {Localization} {Using} {On}-{Board} {Microphones}},
	volume = {30},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2022.3140550},
	abstract = {This paper presents a sound source localization method using an irregular microphone array embedded in a drone. Sound source localization is an integral function of drone audition systems which enables various applications of drones such as search and rescue missions. However, the audio recordings using the on-board microphones obscure the sound emitted by a source on the ground due to drone generated motor and propeller noise, thus leading to an extremely low signal-to-drone noise ratio (SdNR). In this paper, we propose a cross-correlation based direction of arrival (DOA) estimation technique using the time difference of arrival (TDOA) at different microphone pairs, with noise angular spectrum subtraction. Through the measured current-specific drone noise spectrum, noise suppression has been achieved from the multi-channel recordings. Experimental results show that the proposed method is capable of estimating the position in three-dimensional space for simultaneously active multiple sound sources on the ground at low SdNR conditions (-30 dB), and localize two sound sources located at a certain azimuth angular separation with low prediction error comparable to the multiple signal classification (MUSIC) based algorithms and the generalized cross-correlation with phase transformation (GCC-PHAT) method. Due to its simplicity, applicability to any array geometry, and better robustness against drone noise, the proposed method increases the feasibility of localization under extreme SdNR levels.},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Manamperi, Wageesha and Abhayapala, Thushara D. and Zhang, Jihui and Samarasinghe, Prasanga N.},
	year = {2022},
	pages = {508--519},
}

@inproceedings{gustafsson_direction_2015,
	title = {Direction of arrival estimation in sensor arrays using local series expansion of the received signal},
	abstract = {A local series expansion of a received signal is proposed for computing direction of arrival (DOA) in sensor arrays. The advantages compared to classical DOA estimation methods include general sensor configurations, ultra-slow sampling, small dimension of the arrays, and that it applies for both narrowband and wideband signals without prior knowledge of the signals. This makes the method well suited for DOA estimation in sensor networks where size and energy consumption have to be small. We generalize the common far-field assumption of the target to also include the near-field, which enables target tracking using a network of sensor arrays in one framework.},
	booktitle = {2015 18th {International} {Conference} on {Information} {Fusion} ({Fusion})},
	author = {Gustafsson, Fredrik and Hendeby, Gustaf and Lindgren, David and Mathai, George and Habberstad, Hans},
	month = jul,
	year = {2015},
	pages = {761--766},
}

@inproceedings{ishi_evaluation_2009,
	title = {Evaluation of a {MUSIC}-based real-time sound localization of multiple sound sources in real noisy environments},
	doi = {10.1109/IROS.2009.5354309},
	abstract = {With the goal of improving human-robot speech communication, the localization of multiple sound sources in the 3D-space based on the MUSIC algorithm was implemented and evaluated in a humanoid robot embedded in real noisy environments. The effects of several parameters related to the MUSIC algorithm on sound source localization and real-time performances were evaluated, for recordings in different environments. Real-time processing could be achieved by reducing the frame size to 4 ms, without degrading the sound localization performance. A method was also proposed for determination of the number of sources, which is an important parameter that influences the performance of the MUSIC algorithm. The proposed method achieved localization accuracies and insertion rates comparable with the case where the ideal number of sources is given.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Ishi, Carlos T. and Chatot, Olivier and Ishiguro, Hiroshi and Hagita, Norihiro},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0866},
	pages = {2027--2032},
}

@inproceedings{ishi_effects_2011,
	title = {The effects of microphone array processing on pitch extraction in real noisy environments},
	doi = {10.1109/IROS.2011.6094950},
	abstract = {Pitch extraction is important for communication robots, since pitch may carry information about intention, attitude or emotion expression from the user's speech. However, current pitch extraction methods are not robust enough in real noisy environments. In the present work, we propose pitch extraction methods by combining microphone array and auditory scene analysis technologies, and evaluate pitch extraction of multiple speakers in real noisy environments. Evaluation results show that the proposed ML-PSACF (maximum likelihood adaptive beamformer with peak-pruned summary autocorrelation function) contributes to reduce the effects of interference and noise, leading to improvements of 23\%±5\% on pitch estimation rates, in comparison to the baseline of not using array processing.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Ishi, Carlos T. and Liang, Dong and Ishiguro, Hiroshi and Hagita, Norihiro},
	month = sep,
	year = {2011},
	note = {ISSN: 2153-0866},
	pages = {550--555},
}

@inproceedings{ishi_using_2013,
	title = {Using multiple microphone arrays and reflections for {3D} localization of sound sources},
	doi = {10.1109/IROS.2013.6696919},
	abstract = {We proposed a method for estimating sound source locations in a 3D space by integrating sound directions estimated by multiple microphone arrays and taking advantage of reflection information. Two types of sources with different directivity properties (human speech and loudspeaker speech) were evaluated for different positions and orientations. Experimental results showed the effectiveness of using reflection information, depending on the position and orientation of the sound sources relative to the array, walls, and the source type. The use of reflection information increased the source position detection rates by 10\% on average and up to 60\% for the best case.},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Ishi, Carlos T. and Even, Jani and Hagita, Norihiro},
	month = nov,
	year = {2013},
	note = {ISSN: 2153-0866},
	pages = {3937--3942},
}

@inproceedings{nakamura_intelligent_2009,
	title = {Intelligent sound source localization for dynamic environments},
	doi = {10.1109/IROS.2009.5354419},
	abstract = {As robotic technology plays an increasing role in human lives, ¿robot audition¿, human-robot communication, is of great interest, and robot audition needs to be robust and adaptable for dynamic environments. This paper addresses sound source localization working in dynamic environments for robots. Previously, noise robustness and dynamic localized sound selection have been enormous issues for practical use. To correct the issues, a new localization system ¿Selective Attention System¿ is proposed. The system has four new functions: localization with Generalized EigenValue Decomposition of correlation matrices for noise robustness(¿Localization with GEVD¿), sound source cancellation and focus (¿Target Source Selection¿), human-like dynamic Focus of Attention (¿Dynamic FoA¿), and correlation matrix estimation for robotic head rotation (¿Correlation Matrix Estimation¿). All are achieved by the dynamic design of correlation matrices. The system is implemented into a humanoid robot, and the experimental validation is successfully verified even when the robot microphones move dynamically.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Nakamura, Keisuke and Nakadai, Kazuhiro and Asano, Futoshi and Hasegawa, Yuji and Tsujino, Hiroshi},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0866},
	pages = {664--669},
}

@inproceedings{nakamura_intelligent_2011,
	title = {Intelligent {Sound} {Source} {Localization} and its application to multimodal human tracking},
	doi = {10.1109/IROS.2011.6094558},
	abstract = {We have assessed robust tracking of humans based on intelligent Sound Source Localization (SSL) for a robot in a real environment. SSL is fundamental for robot audition, but has three issues in a real environment: robustness against noise with high power, lack of a general framework for selective listening to sound sources, and tracking of inactive and/or noisy sound sources. To address the first issue, we extended Multiple SIgnal Classification by incorporating Generalized EigenValue Decomposition (GEVD-MUSIC) so that it can deal with high power noise and can select target sound sources. To address the second issue, we proposed Sound Source Identification (SSI) based on hierarchical gaussian mixture models and integrated it with GEVD-MUSIC to realize a selective listening function. To address the third issue, we integrated audio-visual human tracking using particle filtering. Integration of these three techniques into an intelligent human tracking system showed: 1) GEVD-MUSIC improved the noise-robustness of SSL by a signal-to-noise ratio of 5-6 dB; 2) SSI performed more than 70\% in F-measure even in a noisy environment; and 3) audio-visual integration improved the average tracking error by approximately 50\%.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Nakamura, Keisuke and Nakadai, Kazuhiro and Asano, Futoshi and Ince, Gökhan},
	month = sep,
	year = {2011},
	note = {ISSN: 2153-0866},
	pages = {143--148},
}

@inproceedings{nakamura_real-time_2012,
	title = {Real-time super-resolution {Sound} {Source} {Localization} for robots},
	doi = {10.1109/IROS.2012.6385494},
	abstract = {Sound Source Localization (SSL) is an essential function for robot audition and yields the location and number of sound sources, which are utilized for post-processes such as sound source separation. SSL for a robot in a real environment mainly requires noise-robustness, high resolution and real-time processing. A technique using microphone array processing, that is, Multiple Signal Classification based on Standard EigenValue Decomposition (SEVD-MUSIC) is commonly used for localization. We improved its robustness against noise with high power by incorporating Generalized EigenValue Decomposition (GEVD). However, GEVD-based MUSIC (GEVD-MUSIC) has mainly two issues: 1) the resolution of pre-measured Transfer Functions (TFs) determines the resolution of SSL, 2) its computational cost is expensive for real-time processing. For the first issue, we propose a TF interpolation method integrating time-domain-based and frequency-domain-based interpolation. The interpolation achieves super-resolution SSL, whose resolution is higher than that of the pre-measured TFs. For the second issue, we propose two methods, MUSIC based on Generalized Singular Value Decomposition (GSVD-MUSIC), and Hierarchical SSL (H-SSL). GSVD-MUSIC drastically reduces the computational cost while maintaining noise-robustness in localization. H-SSL also reduces the computational cost by introducing a hierarchical search algorithm instead of using greedy search in localization. These techniques are integrated into an SSL system using a robot embedded microphone array. The experimental result showed: the proposed interpolation achieved approximately 1 degree resolution although we have only TFs at 30 degree intervals, GSVD-MUSIC attained 46.4\% and 40.6\% of the computational cost compared to SEVD-MUSIC and GEVD-MUSIC, respectively, H-SSL reduces 59.2\% computational cost in localization of a single sound source.},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Nakamura, Keisuke and Nakadai, Kazuhiro and Ince, Gökhan},
	month = oct,
	year = {2012},
	note = {ISSN: 2153-0866},
	pages = {694--699},
}

@article{suzuki_influence_2017,
	title = {Influence of {Different} {Impulse} {Response} {Measurement} {Signals} on {MUSIC}-{Based} {Sound} {Source} {Localization}},
	volume = {29},
	doi = {10.20965/jrm.2017.p0072},
	number = {1},
	journal = {Journal of Robotics and Mechatronics},
	author = {Suzuki, Takuya and Otsuka, Hiroaki and Akahori, Wataru and Bando, Yoshiaki and Okuno, Hiroshi G.},
	year = {2017},
	pages = {72--82},
}

@article{lee_subspace-based_2015,
	title = {Subspace-based {DOA} with linear phase approximation and frequency bin selection preprocessing for interactive robots in noisy environments},
	volume = {34},
	issn = {0885-2308},
	url = {https://www.sciencedirect.com/science/article/pii/S0885230815000224},
	doi = {https://doi.org/10.1016/j.csl.2015.03.002},
	abstract = {This work develops a method of estimating subspace-based direction of arrival (DOA) that uses two proposed preprocesses. The method can be used in applications that involve interactive robots to calculate the direction to a noise-contaminated signal in noisy environments. The proposed method can be divided into two parts, which are linear phase approximation and frequency bin selection. Linear phase approximation rectifies the phases of the two-channel signals that are affected by noise, and reconstructs the covariance matrix of the received signals according to the compensative phases using phase line regression. To increase the accuracy of DOA result, a method of frequency bin selection that is based on eigenvalue decomposition (EVD) is utilized to detect and filter out the noisy frequency bins of the microphone signals. The proposed techniques are adopted in a method of subspace-based DOA estimation that is called multiple signal classification (MUSIC). Experimental results reveal that the mean estimation error obtained using proposed method can be reduced by 7.61° from the conventional MUSIC method. The proposed method is compared with the covariance-based DOA method that is called the minimum variance distortionless response (MVDR). The DOA improves the mean estimation accuracy by 4.98° relative to the conventional MVDR method. The experimental results demonstrate that both subspace-based and covariance-based DOA algorithms with the proposed preprocessing method outperform the DOA estimation in detecting the direction of signal in a noisy environment.},
	number = {1},
	journal = {Computer Speech \& Language},
	author = {Lee, Sheng-Chieh and Chen, Bo-Wei and Wang, Jhing-Fa and Liao, Min-Jian and Ji, Wen},
	year = {2015},
	keywords = {Angular correction, Covariance matrix reconstruction, Direction of arrival (DOA), Frequency bin selection, Human–robot interaction, Interactive robot, Linear phase approximation, Sound source location},
	pages = {113--128},
}

@inproceedings{vincent_audio_2015,
	title = {Audio source localization by optimal control of a mobile robot},
	doi = {10.1109/ICASSP.2015.7179049},
	abstract = {We consider the task of audio source localization using a microphone array on a mobile robot. Active localization algorithms have been proposed in the literature that can estimate the 3D position of a source by fusing the measurements taken for different poses of the robot. The robot movements are typically fixed, however, or they obey heuristic strategies, such as turning the head and moving towards the source, which may be suboptimal. In this paper, we propose to control the robot movements so as to locate the source as quickly as possible. We represent the belief about the source position by a discrete grid and we introduce a dynamic programming algorithm to find the optimal robot motion minimizing the entropy of the grid. We report initial results in a real environment.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Vincent, Emmanuel and Sini, Aghilas and Charpillet, François},
	month = apr,
	year = {2015},
	note = {ISSN: 2379-190X},
	pages = {5630--5634},
}

@inproceedings{pourmehr_sensor_2015,
	title = {A sensor fusion framework for finding an {HRI} partner in crowd},
	booktitle = {{IEEE} {Int}. {Conf}. on {Intelligent} {Robots} and {Systems}, {Workshop} on {Designing} and {Evaluating} {Social} {Robots} for {Public} {Settings}},
	author = {Pourmehr, Shokoofeh and Bruce, Jake and Wawerla, Jens and Vaughan, Richard},
	year = {2015},
}
